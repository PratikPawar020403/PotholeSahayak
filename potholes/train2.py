###############COLAB##################

# -*- coding: utf-8 -*-
"""correctpot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IhXLnR_qCKyL7kYLDTtP8Kxjda_kswc2
"""

# Install ultralytics and other dependencies
!pip install -q ultralytics kaggle

# Suppress warnings for a cleaner output
import warnings
warnings.filterwarnings('ignore')

# Standard library imports
import os
import shutil
import random
import yaml
from collections import deque

# Data and plotting libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(rc={'axes.facecolor': '#ffe4de'}, style='darkgrid')

# Computer vision and image processing libraries
import cv2
from PIL import Image
from IPython.display import Image as IPImage, display, Video

# Import the YOLO model from ultralytics
from ultralytics import YOLO

# Upload your Kaggle API key (kaggle.json) when prompted
from google.colab import files
files.upload()  # Upload your kaggle.json file

# Configure Kaggle API credentials
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset from Kaggle
!kaggle datasets download -d farzadnekouei/pothole-image-segmentation-dataset

# Unzip the dataset into /content/pothole_dataset folder
!unzip -o pothole-image-segmentation-dataset.zip -d /content/pothole_dataset

# List the directory structure to verify extraction
!find /content/pothole_dataset -type d

# Define the path to the dataset YAML configuration file
yaml_file_path = '/content/pothole_dataset/Pothole_Segmentation_YOLOv8/data.yaml'

# Load and print YAML content
with open(yaml_file_path, 'r') as file:
    data = yaml.safe_load(file)
print("Dataset YAML Configuration:")
print(data)

# Define class names for display (update if you have multiple classes)
names = ['Pothole']

# Define paths for training images and labels
image_dir = '/content/pothole_dataset/Pothole_Segmentation_YOLOv8/train/images'
label_dir = '/content/pothole_dataset/Pothole_Segmentation_YOLOv8/train/labels'

# Get list of image filenames
image_files = os.listdir(image_dir)
if len(image_files) < 25:
    raise ValueError("Not enough images to sample. Please check your dataset.")

# Randomly sample 25 images
random_images = random.sample(image_files, 25)

# Setup a 5x5 grid for plotting
fig, axs = plt.subplots(5, 5, figsize=(20,20))

for i, image_file in enumerate(random_images):
    row = i // 5
    col = i % 5
    image_path = os.path.join(image_dir, image_file)
    image = cv2.imread(image_path)

    # Construct corresponding label file path (assumes .txt labels)
    label_file = os.path.splitext(image_file)[0] + ".txt"
    label_path = os.path.join(label_dir, label_file)

    # Read and process the labels (if the file exists)
    if os.path.exists(label_path):
        with open(label_path, "r") as f:
            labels = f.read().strip().split("\n")
        for label in labels:
            parts = label.split()
            if len(parts) != 5:
                continue
            class_id, x_center, y_center, width, height = map(float, parts)
            # Calculate bounding box coordinates
            x_min = int((x_center - width/2) * image.shape[1])
            y_min = int((y_center - height/2) * image.shape[0])
            x_max = int((x_center + width/2) * image.shape[1])
            y_max = int((y_center + height/2) * image.shape[0])
            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 3)
            cv2.putText(image, names[int(class_id)], (x_min, y_min - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)

    axs[row, col].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    axs[row, col].axis('off')

plt.tight_layout()
plt.show()

# Define paths for training and validation images
dataset_path = '/content/pothole_dataset/Pothole_Segmentation_YOLOv8'
train_images_path = os.path.join(dataset_path, 'train', 'images')
valid_images_path = os.path.join(dataset_path, 'valid', 'images')

num_train_images = 0
num_valid_images = 0
train_image_sizes = set()
valid_image_sizes = set()

# Process training images
for filename in os.listdir(train_images_path):
    if filename.endswith('.jpg'):
        num_train_images += 1
        image_path = os.path.join(train_images_path, filename)
        with Image.open(image_path) as img:
            train_image_sizes.add(img.size)

# Process validation images
for filename in os.listdir(valid_images_path):
    if filename.endswith('.jpg'):
        num_valid_images += 1
        image_path = os.path.join(valid_images_path, filename)
        with Image.open(image_path) as img:
            valid_image_sizes.add(img.size)

print(f"Number of training images: {num_train_images}")
print(f"Number of validation images: {num_valid_images}")

if len(train_image_sizes) == 1:
    print(f"All training images have the same size: {train_image_sizes.pop()}")
else:
    print("Training images have varying sizes.")

if len(valid_image_sizes) == 1:
    print(f"All validation images have the same size: {valid_image_sizes.pop()}")
else:
    print("Validation images have varying sizes.")

# Initialize the YOLO segmentation model (using the 's' variant)
model = YOLO('yolov8s-seg.pt')  # This downloads weights if not present

# Train the model using the YAML configuration file
results = model.train(
    data=yaml_file_path,   # Path to your YAML config file
    epochs=137,            # Number of training epochs
    imgsz=640,             # Image size for training
    patience=15,           # Early stopping patience
    batch=16,              # Batch size
    optimizer='auto',      # Let YOLO choose the best optimizer
    lr0=0.0001,            # Initial learning rate
    lrf=0.01,              # Final learning rate fraction
    dropout=0.25,          # Dropout probability
    device=0,              # GPU device (0 for first GPU)
    seed=42                # Random seed for reproducibility
)

# Display the training results image
# (Make sure the path below matches your training run output directory)
display(IPImage(filename='/content/runs/segment/train/results.png', width=1000))

# Define path to the best model weights from training
best_model_path = '/content/runs/segment/train/weights/best.pt'

# Load the best model
best_model = YOLO(best_model_path)

# Validate the best model on the validation split
metrics = best_model.val(split='val')

# Print key metrics
print(f"Mean Average Precision @.5:.95 : {metrics.box.map}")
print(f"Mean Average Precision @ .50   : {metrics.box.map50}")
print(f"Mean Average Precision @ .70   : {metrics.box.map75}")
print("Recall:", metrics.box.r)
print("F1 Score:", metrics.box.f1)
print("All MAP metrics:", metrics.box.maps)

# Optionally, create a DataFrame for further analysis
metrics_df = pd.DataFrame.from_dict(metrics.results_dict, orient='index', columns=['Metric Value'])
print(metrics_df.round(3))

# Define the validation image directory for inference
val_image_dir = '/content/pothole_dataset/Pothole_Segmentation_YOLOv8/valid/images'
all_images = os.listdir(val_image_dir)

# Select a subset of images for inference (e.g., first 45 images)
selected_images = all_images[:45]

# Loop over selected images, run prediction, and display results
for img_name in selected_images:
    img_path = os.path.join(val_image_dir, img_name)
    results = best_model.predict(img_path)

    # Read the image for visualization
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Plot each result (if multiple detections, each result is plotted)
    for result in results:
        plotted_img = result.plot()  # This method returns the image with detections
        plt.figure(figsize=(10,9))
        plt.imshow(plotted_img)
        plt.axis('off')
        plt.title(img_name)
        plt.show()

# =============================================================================
# Inference on Video Files with Upload Option (Improved Debugging)
# =============================================================================
import glob  # Ensure glob is imported
import locale  # Import the locale module
from google.colab import files
uploaded_videos = files.upload()

# Set the locale to UTF-8 before running shell commands
locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')

for video_filename in uploaded_videos.keys():
    print(f"Processing video file: {video_filename}")

    # Run inference on the video file.
    # 'source' accepts a video file path. 'save=True' will store the result.
    video_results = best_model.predict(source=video_filename, show=False, save=True)
    print("Inference complete for:", video_filename)

    # By default, YOLO might save processed video results in a subdirectory under runs/segment/predict.
    results_dir = '/content/runs/segment/predict'

    # Search recursively for .mp4 files in the results directory
    processed_videos = glob.glob(os.path.join(results_dir, '**', '*.mp4'), recursive=True)
    if processed_videos:
        latest_video = max(processed_videos, key=os.path.getctime)
        print("Displaying processed video:", latest_video)
        display(Video(latest_video, embed=True, width=600, height=400))
    else:
        print("No processed video file found in", results_dir)
        # Optional: list all files under the results directory for debugging
        print("Files in results directory:")
        !find /content/runs/segment/predict -type f # The ! command now runs in a UTF-8 locale

from google.colab import files
files.download('/content/runs/segment/train/weights/best.pt')

